gen_data_dir: "TowerEval-Data-v0.1/data/instructions_data/5_shot"
eval_data_dir: "TowerEval-Data-v0.1/data/raw_data"
gen_output_dir: "TowerEval-Data-v0.1/generations/5_shot"
eval_output_dir: "TowerEval-Data-v0.1/evaluations/5_shot"
tasks: 
  - name: ape
    subtasks:
      nllb_3b_wmt23.de-en:
      nllb_3b_wmt23.en-de: 
      nllb_3b_wmt23.en-zh: 
        eval_args:
          metrics:
            ter:
              asian_support: True
            chrf:
            bleu:
              tokenizer: zh
            comet:
              batch_size: 16
            comet_kiwi:
              batch_size: 16
      nllb_3b_wmt23.ru-en:
    metrics:
      ter:
        asian_support: True
      chrf:
      comet:
        batch_size: 16
      comet_kiwi:
        batch_size: 16
      bleu:
models:
  - name: TowerBase-7B-v0.1
    type: vllm
    arguments:
      model_dir: Unbabel/TowerBase-7B-v0.1
      n_gpus: 1
      max_tokens: 1024
      run_async: True
      batch_size: -1
  - name: llama2-7b-hf
    type: vllm
    arguments:
      model_dir: meta-llama/Llama-2-7b-hf
      n_gpus: 1
      max_tokens: 1024
      run_async: True
      batch_size: -1
  - name: llama2-13b-hf
    type: vllm
    arguments:
      model_dir: meta-llama/Llama-2-13b-hf
      n_gpus: 1
      max_tokens: 1024
      run_async: True
      batch_size: -1
  - name: llama2-70b-hf
    type: vllm
    arguments:
      model_dir: meta-llama/Llama-2-70b-hf
      n_gpus: 2
      max_tokens: 1024
      run_async: True
      batch_size: -1
  - name: mixtral-8x7B-v0.1
    type: vllm
    arguments:
      model_dir: mistralai/Mixtral-8x7B-v0.1
      n_gpus: 2
      max_tokens: 1024
      run_async: True
      batch_size: -1